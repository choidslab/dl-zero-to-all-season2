{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Logistic Regression(Classification)\n",
    "  - Binary Classification, Multi Label(Class) Classification\n",
    "  - Data set 설정\n",
    "  - matplotlib을 이용하여 데이터셋 분포 그래프 표시"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "2.1.0\n",
      "Iter: 0, Loss: 0.6874\n",
      "Iter: 10, Loss: 0.6507\n",
      "Iter: 20, Loss: 0.6331\n",
      "Iter: 30, Loss: 0.6223\n",
      "Iter: 40, Loss: 0.6140\n",
      "Iter: 50, Loss: 0.6069\n",
      "Iter: 60, Loss: 0.6004\n",
      "Iter: 70, Loss: 0.5943\n",
      "Iter: 80, Loss: 0.5884\n",
      "Iter: 90, Loss: 0.5829\n",
      "Iter: 100, Loss: 0.5776\n",
      "Iter: 110, Loss: 0.5725\n",
      "Iter: 120, Loss: 0.5676\n",
      "Iter: 130, Loss: 0.5629\n",
      "Iter: 140, Loss: 0.5584\n",
      "Iter: 150, Loss: 0.5541\n",
      "Iter: 160, Loss: 0.5499\n",
      "Iter: 170, Loss: 0.5459\n",
      "Iter: 180, Loss: 0.5421\n",
      "Iter: 190, Loss: 0.5384\n",
      "Iter: 200, Loss: 0.5349\n",
      "Iter: 210, Loss: 0.5314\n",
      "Iter: 220, Loss: 0.5281\n",
      "Iter: 230, Loss: 0.5249\n",
      "Iter: 240, Loss: 0.5219\n",
      "Iter: 250, Loss: 0.5189\n",
      "Iter: 260, Loss: 0.5160\n",
      "Iter: 270, Loss: 0.5132\n",
      "Iter: 280, Loss: 0.5105\n",
      "Iter: 290, Loss: 0.5079\n",
      "Iter: 300, Loss: 0.5054\n",
      "Iter: 310, Loss: 0.5030\n",
      "Iter: 320, Loss: 0.5006\n",
      "Iter: 330, Loss: 0.4983\n",
      "Iter: 340, Loss: 0.4960\n",
      "Iter: 350, Loss: 0.4939\n",
      "Iter: 360, Loss: 0.4917\n",
      "Iter: 370, Loss: 0.4897\n",
      "Iter: 380, Loss: 0.4877\n",
      "Iter: 390, Loss: 0.4857\n",
      "Iter: 400, Loss: 0.4838\n",
      "Iter: 410, Loss: 0.4820\n",
      "Iter: 420, Loss: 0.4802\n",
      "Iter: 430, Loss: 0.4784\n",
      "Iter: 440, Loss: 0.4767\n",
      "Iter: 450, Loss: 0.4750\n",
      "Iter: 460, Loss: 0.4734\n",
      "Iter: 470, Loss: 0.4718\n",
      "Iter: 480, Loss: 0.4702\n",
      "Iter: 490, Loss: 0.4686\n",
      "Iter: 500, Loss: 0.4671\n",
      "Iter: 510, Loss: 0.4657\n",
      "Iter: 520, Loss: 0.4642\n",
      "Iter: 530, Loss: 0.4628\n",
      "Iter: 540, Loss: 0.4614\n",
      "Iter: 550, Loss: 0.4600\n",
      "Iter: 560, Loss: 0.4587\n",
      "Iter: 570, Loss: 0.4574\n",
      "Iter: 580, Loss: 0.4561\n",
      "Iter: 590, Loss: 0.4548\n",
      "Iter: 600, Loss: 0.4535\n",
      "Iter: 610, Loss: 0.4523\n",
      "Iter: 620, Loss: 0.4511\n",
      "Iter: 630, Loss: 0.4499\n",
      "Iter: 640, Loss: 0.4487\n",
      "Iter: 650, Loss: 0.4476\n",
      "Iter: 660, Loss: 0.4464\n",
      "Iter: 670, Loss: 0.4453\n",
      "Iter: 680, Loss: 0.4442\n",
      "Iter: 690, Loss: 0.4431\n",
      "Iter: 700, Loss: 0.4420\n",
      "Iter: 710, Loss: 0.4410\n",
      "Iter: 720, Loss: 0.4399\n",
      "Iter: 730, Loss: 0.4389\n",
      "Iter: 740, Loss: 0.4378\n",
      "Iter: 750, Loss: 0.4368\n",
      "Iter: 760, Loss: 0.4358\n",
      "Iter: 770, Loss: 0.4348\n",
      "Iter: 780, Loss: 0.4338\n",
      "Iter: 790, Loss: 0.4329\n",
      "Iter: 800, Loss: 0.4319\n",
      "Iter: 810, Loss: 0.4310\n",
      "Iter: 820, Loss: 0.4300\n",
      "Iter: 830, Loss: 0.4291\n",
      "Iter: 840, Loss: 0.4282\n",
      "Iter: 850, Loss: 0.4272\n",
      "Iter: 860, Loss: 0.4263\n",
      "Iter: 870, Loss: 0.4254\n",
      "Iter: 880, Loss: 0.4245\n",
      "Iter: 890, Loss: 0.4237\n",
      "Iter: 900, Loss: 0.4228\n",
      "Iter: 910, Loss: 0.4219\n",
      "Iter: 920, Loss: 0.4211\n",
      "Iter: 930, Loss: 0.4202\n",
      "Iter: 940, Loss: 0.4194\n",
      "Iter: 950, Loss: 0.4185\n",
      "Iter: 960, Loss: 0.4177\n",
      "Iter: 970, Loss: 0.4169\n",
      "Iter: 980, Loss: 0.4160\n",
      "Iter: 990, Loss: 0.4152\n",
      "Iter: 1000, Loss: 0.4144\n",
      "Testset Accuracy: 1.0000\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777)  # for reproducibility\n",
    "print(tf.__version__)\n",
    "\n",
    "x_train = [[1., 2.],\n",
    "          [2., 3.],\n",
    "          [3., 1.],\n",
    "          [4., 3.],\n",
    "          [5., 3.],\n",
    "          [6., 2.]]\n",
    "y_train = [[0.],\n",
    "          [0.],\n",
    "          [0.],\n",
    "          [1.],\n",
    "          [1.],\n",
    "          [1.]]\n",
    "\n",
    "x_test = [[5.,2.]]\n",
    "y_test = [[1.]]\n",
    "\n",
    "\n",
    "x1 = [x[0] for x in x_train]\n",
    "x2 = [x[1] for x in x_train]\n",
    "\n",
    "colors = [int(y[0] % 3) for y in y_train]\n",
    "plt.scatter(x1,x2, c=colors , marker='^')\n",
    "plt.scatter(x_test[0][0],x_test[0][1], c=\"red\")\n",
    "\n",
    "plt.xlabel(\"x1\")\n",
    "plt.ylabel(\"x2\")\n",
    "plt.show()\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))#.repeat()\n",
    "W = tf.Variable(tf.zeros([2,1]), name='weight')\n",
    "b = tf.Variable(tf.zeros([1]), name='bias')\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "epoch = 1001\n",
    "\n",
    "def logistic_regression(features):\n",
    "    hypothesis = tf.divide(1., 1. + tf.exp(tf.matmul(features, W) + b))\n",
    "    return hypothesis\n",
    "\n",
    "def loss_function(hypothesis, features, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(logistic_regression(features)) + (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "def accuracy_fn(hypothesis, labels):\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.int32))\n",
    "    return accuracy\n",
    "\n",
    "def grad(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_value = loss_function(logistic_regression(features), features, labels)\n",
    "        return tape.gradient(loss_value, [W, b])\n",
    "\n",
    "for step in range(epoch):\n",
    "    for features, labels in iter(dataset):\n",
    "        grads = grad(features, labels)\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "        if step % 10 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_function(logistic_regression(features),features,labels)))\n",
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}